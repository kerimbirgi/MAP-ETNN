# @package _global_

eval_only: false

training:
  epochs: 100
  batch_size: 4
  weight_decay: 1e-16
  scheduler_mode: 'cosine_warmup'
  optimizer: 'AdamW'
  min_lr: 1e-6
  num_lr_cycles: 1
  clip_gradients: true
  clip_amount: 1.0
  lr: 3e-4
  crit: 'MSE'
  early_stop: true
  early_stop_patience: 20
  normalize_targets: false
  gradient_accumulate: false
  